# -*- coding: utf-8 -*-
"""AI-DRIVEN NATURAL LANGUAGE PROCESSING PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PmLTg2JKXp3cd0YAEzXDn0G9yT59XM6R
"""

!pip install langchain openai transformers torch sentence-transformers

from transformers import pipeline
from sentence_transformers import SentenceTransformer, util
import torch

"""
Selected Language Models:
1. DistilBERT – Sentiment Analysis (Classification)
2. FLAN-T5 – Text Generation (Instruction-based)

Reason:
- Open-source
- Free to use
- Strong NLP foundations
- Suitable for academic researc

"""

sentiment_model = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

sentiment_model("This project is extremely well structured and informative")

text_generator = pipeline(
    "text2text-generation",
    model="google/flan-t5-base",
    device=0 if torch.cuda.is_available() else -1
)

text_generator("Explain Artificial Intelligence in simple words")

text_generator("Explain AI to a 10 year old")[0]["generated_text"]
text_generator("Explain AI using mathematical concepts")[0]["generated_text"]

test_prompts = [
    "Explain Artificial Intelligence",
    "Explain AI to a school student",
    "Explain AI using statistics",
    "Is AI dangerous?"
]

for prompt in test_prompts:
    print("\nPROMPT:", prompt)
    print("OUTPUT:", text_generator(prompt)[0]["generated_text"])

"""
Observations:
- Simple prompts → Clear and accurate
- Child-friendly prompts → Simplified responses
- Technical prompts → Reasonable explanations
- Ethical prompts → Neutral and cautious responses

Limitations:
- Shorter responses
- Less creativity compared to GPT models
"""

embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

sentences = [
    "Artificial intelligence is a branch of computer science",
    "AI studies intelligent machines",
    "Cricket is a popular sport in India"
]

embeddings = embedding_model.encode(sentences)

similarity_1 = util.cos_sim(embeddings[0], embeddings[1])
similarity_2 = util.cos_sim(embeddings[0], embeddings[2])

print("Similarity (AI vs AI):", similarity_1.item())
print("Similarity (AI vs Cricket):", similarity_2.item())

"""
Research Questions:

1. How effective is DistilBERT for sentiment analysis?
→ High accuracy with fast inference.

2. Can FLAN-T5 handle diverse prompt styles?
→ Yes, especially instruction-based prompts.

3. What are the limitations of open-source LMs?
→ Short context window and limited creativity.

4. Are embeddings effective for semantic similarity?
→ Yes, strong performance on related texts.
"""



"""Project Alignment:
- Demonstrates NLP fundamentals
- Uses transformer architectures
- Encourages open-source AI
- Supports responsible ML research

Conclusion:
- Open-source LMs are powerful for academic use
- Different models serve different NLP tasks
- Prompt engineering improves results significantly

Applications:
- Chatbots
- Sentiment analysis
- Search systems
- Educational tools

Future Work:
- Fine-tuning models
- Retrieval-Augmented Generation
- Comparing with LLaMA/Mistral
"""