# -*- coding: utf-8 -*-
"""LOAN APPROVAL PREDICTION WITH MACHINE LEARNING.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m6Gevs6tLMs4AZZrZRaWTGPzyzhO52qG
"""

# ==============================
# Loan Approval Prediction
# ==============================

# 1. Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ------------------------------
# 2. Load Dataset
# ------------------------------
df = pd.read_csv("/content/loan_data_set.csv")

print("Dataset Head:")
print(df.head())

# ------------------------------
# 3. Basic Information
# ------------------------------
print("\nDataset Info:")
print(df.info())

print("\nMissing Values:")
print(df.isnull().sum())

# ------------------------------
# 4. Data Preprocessing
# ------------------------------

# Drop irrelevant column
df.drop("Loan_ID", axis=1, inplace=True)

# Fill categorical missing values with mode
cat_cols = ['Gender', 'Married', 'Dependents', 'Self_Employed',
            'Loan_Amount_Term', 'Credit_History']

for col in cat_cols:
    df[col].fillna(df[col].mode()[0], inplace=True)

# Fill numerical missing values with median
df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True)

# ------------------------------
# 5. Outlier Handling (IQR - ApplicantIncome)
# Given:
# Q1 = 5.35, Q3 = 6.27, IQR = 0.925
# Lower = 3.96, Upper = 7.66
# ------------------------------

df['ApplicantIncome_log'] = np.log(df['ApplicantIncome'])

lower_limit = 3.96
upper_limit = 7.66

df = df[
    (df['ApplicantIncome_log'] >= lower_limit) &
    (df['ApplicantIncome_log'] <= upper_limit)
]

# ------------------------------
# 6. Exploratory Data Analysis
# ------------------------------

# Loan Status Distribution
sns.countplot(x='Loan_Status', data=df)
plt.title("Loan Approval Distribution")
plt.show()

# Credit History vs Loan Status
sns.countplot(x='Credit_History', hue='Loan_Status', data=df)
plt.title("Credit History vs Loan Status")
plt.show()

# ------------------------------
# 7. Feature Engineering
# ------------------------------
df_encoded = pd.get_dummies(df, drop_first=True)

# ------------------------------
# 8. Split Features & Target
# ------------------------------
X = df_encoded.drop('Loan_Status_Y', axis=1)
y = df_encoded['Loan_Status_Y']

# ------------------------------
# 9. Train-Test Split
# ------------------------------
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# ------------------------------
# 10. Feature Scaling
# ------------------------------
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ------------------------------
# 11. Model Training
# ------------------------------
model = RandomForestClassifier(
    n_estimators=200,
    random_state=42
)

model.fit(X_train, y_train)

# ------------------------------
# 12. Prediction
# ------------------------------
y_pred = model.predict(X_test)

# ------------------------------
# 13. Model Evaluation
# ------------------------------
accuracy = accuracy_score(y_test, y_pred)
print("\nModel Accuracy:", accuracy)

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()